{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(In order to load the stylesheet of this notebook, execute the last code cell in this notebook)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyzing Hotel Ratings on Tripadvisor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this homework we will focus on practicing two techniques: web scraping and regression. For the first part, we will get some basic information for each hotel in Boston. Then, we will fit a regression model on this information and try to analyze it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Task 1 (30 pts)**\n",
    "\n",
    "We will scrape the data using Beautiful Soup. For each hotel that our search returns, we will get the information below.\n",
    "\n",
    "![Information to be scraped](hotel_info.png)\n",
    "\n",
    "Of course, feel free to collect even more data if you want. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import urllib2\n",
    "import csv\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from bs4 import BeautifulSoup\n",
    "url_list = []\n",
    "page = urllib2.urlopen('https://www.tripadvisor.com/Hotels-g60745-Boston_Massachusetts-Hotels.html').read()\n",
    "soup = BeautifulSoup(page, \"lxml\")\n",
    "list = soup.findAll('div', attrs = {'class':'prw_rup prw_common_short_cell_thumbnail'})\n",
    "myNext = soup.findAll('a', attrs = {'class':'nav next ui_button primary taLnk'})\n",
    "for s in list:\n",
    "    tmp = BeautifulSoup(str(s),\"lxml\")\n",
    "    tmpList = tmp.findAll('a', href=True)\n",
    "    for element in tmpList:\n",
    "        arr = str(element).split(' ')\n",
    "        tmp_arr = str(arr[1]).split('=')\n",
    "        url = str(tmp_arr[1])[2:-1]\n",
    "        url_list.append(url)\n",
    "        \n",
    "while len(myNext) == 1:\n",
    "    nextTmp = myNext[0]\n",
    "    st = nextTmp.get('href')\n",
    "    url = 'https://www.tripadvisor.com' + st\n",
    "    page = urllib2.urlopen(url).read()\n",
    "    soup = BeautifulSoup(page, \"lxml\")\n",
    "    list = soup.findAll('div', attrs = {'class':'prw_rup prw_common_short_cell_thumbnail'})\n",
    "    myNext = soup.findAll('a', attrs = {'class':'nav next ui_button primary taLnk'})\n",
    "    for s in list:\n",
    "        tmp = BeautifulSoup(str(s),\"lxml\")\n",
    "        tmpList = tmp.findAll('a', href=True)\n",
    "        for element in tmpList:\n",
    "            arr = str(element).split(' ')\n",
    "            tmp_arr = str(arr[1]).split('=')\n",
    "            url = str(tmp_arr[1])[2:-1]\n",
    "            url_list.append(url)\n",
    "        \n",
    "url_list = set(url_list)\n",
    "target_rating = []\n",
    "count = 0;\n",
    "review_url = []\n",
    "for url in url_list:\n",
    "    url = 'https://www.tripadvisor.com/' + url\n",
    "    page = urllib2.urlopen(url).read()\n",
    "    soup = BeautifulSoup(page, \"lxml\")\n",
    "    innerBubble = soup.findAll('div', attrs = {'class':'reviewSelector'})\n",
    "    tmp =  BeautifulSoup(str(innerBubble[0]), \"lxml\")\n",
    "    tmp_page = tmp.findAll('div', attrs = {'class':'quote'})\n",
    "    div = BeautifulSoup(str(tmp_page), \"lxml\")\n",
    "    div_html = BeautifulSoup(str(div), \"lxml\")\n",
    "    buff = div_html.findAll('a', href = True)\n",
    "    #buff[0]['href']\n",
    "    if(len(buff) == 1):\n",
    "        review_url.append(buff[0]['href']);\n",
    "        \n",
    "for url in review_url:\n",
    "    url = 'https://www.tripadvisor.com' + url\n",
    "    page = urllib2.urlopen(url).read()\n",
    "    soup = BeautifulSoup(page, \"lxml\")\n",
    "    element = soup.findAll('div', attrs = {'class':'col rating '})\n",
    "    element = BeautifulSoup(str(element), \"lxml\")\n",
    "    temp = element.findAll('li')\n",
    "    temp = BeautifulSoup(str(temp), \"lxml\")\n",
    "    span = temp.findAll('span', attrs={'class': None})\n",
    "    test = str(span).split('<span>')\n",
    "    \n",
    "    num1 = int(test[1].replace(\",\", \"\"))\n",
    "    num2 = int(test[4].replace(\",\", \"\"))\n",
    "    num3 = int(test[7].replace(\",\", \"\"))\n",
    "    num4 = int(test[10].replace(\",\", \"\"))\n",
    "    num5 = int(test[13].replace(\",\", \"\"))\n",
    "    \n",
    "    y = num1 * 5 + num2 + 4 + num3 * 3 + num4 * 2 + num5 * 1\n",
    "    y = float(y) / (num1 + num2 + num3 + num4 + num5)\n",
    "    y = round(y, 2)\n",
    "    target_rating.append(y)\n",
    "\n",
    "y_df = pd.DataFrame(target_rating)\n",
    "y_df.to_csv('target.csv')  \n",
    "\n",
    "df = pd.DataFrame(review_url)\n",
    "df.to_csv('url.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4.19, 4.9, 4.51, 4.55, 4.62, 4.21]\n",
      "[4.2, 4.55, 4.5, 4.51, 4.68, 4.2]\n",
      "[3.73, 4.72, 3.92, 3.8, 4.37, 3.73]\n",
      "[4.11, 4.49, 3.97, 3.77, 4.48, 4.11]\n",
      "[4.21, 4.87, 4.02, 3.92, 4.54, 4.21]\n",
      "[3.65, 3.38, 3.58, 3.57, 3.9, 3.65]\n",
      "[4.23, 4.67, 4.53, 4.54, 4.74, 4.23]\n",
      "[3.8, 4.63, 4.54, 4.35, 4.68, 3.8]\n",
      "[3.86, 4.43, 4.43, 4.57, 4.57, 3.86]\n",
      "[3.5, 4.0, 3.0, 3.75, 3.75, 3.5]\n",
      "[3.87, 4.91, 4.35, 4.35, 4.74, 3.87]\n",
      "[4.55, 4.88, 4.79, 4.73, 4.83, 4.57]\n",
      "[4.4, 5.0, 4.8, 4.6, 4.8, 4.4]\n",
      "[3.67, 3.67, 4.0, 4.0, 4.0, 3.67]\n",
      "[5.0, 5.0, 5.0, 4.0, 5.0, 5.0]\n",
      "[3.97, 3.64, 4.16, 4.19, 4.37, 3.98]\n",
      "[4.28, 4.82, 4.3, 4.33, 4.61, 4.28]\n",
      "[4.35, 4.91, 4.76, 4.75, 4.92, 4.36]\n",
      "[4.14, 4.95, 4.86, 4.72, 4.86, 4.14]\n",
      "[3, 3, 3, 3, 3, 3]\n",
      "[4.01, 3.44, 3.95, 4.1, 4.26, 4.04]\n",
      "[4.29, 4.67, 4.64, 4.67, 4.82, 4.29]\n",
      "[4.0, 5.0, 4.8, 4.8, 4.8, 4.0]\n",
      "[3.5, 3.5, 4.5, 3.5, 4.0, 3.5]\n",
      "[4.44, 4.79, 4.82, 4.71, 4.82, 4.44]\n",
      "[4.07, 3.79, 4.06, 3.98, 4.31, 4.07]\n",
      "[4.0, 4.0, 4.0, 3.5, 3.67, 4.0]\n",
      "[4.28, 4.84, 4.66, 4.69, 4.85, 4.28]\n",
      "[4.36, 4.87, 4.42, 4.34, 4.68, 4.36]\n",
      "[4.75, 5.0, 4.5, 4.25, 4.75, 4.75]\n",
      "[2.5, 2.5, 3.0, 3.0, 5.0, 2.5]\n",
      "[3.29, 4.44, 3.68, 2.85, 3.23, 3.29]\n",
      "[4.43, 4.26, 4.42, 4.63, 4.74, 4.43]\n",
      "[4.28, 4.9, 4.86, 4.81, 4.85, 4.28]\n",
      "[4.61, 4.87, 4.44, 4.88, 4.89, 4.62]\n",
      "[4.36, 4.74, 4.43, 4.29, 4.6, 4.36]\n",
      "[4.59, 4.72, 4.79, 4.82, 4.89, 4.59]\n",
      "[3.85, 3.58, 4.06, 4.09, 4.2, 3.85]\n",
      "[3.71, 4.5, 4.13, 4.04, 4.28, 3.73]\n",
      "[3.4, 5.0, 3.2, 3.6, 4.0, 3.4]\n",
      "[4.05, 4.42, 4.31, 4.39, 4.42, 4.07]\n",
      "[4.22, 4.44, 4.0, 4.33, 4.67, 4.22]\n",
      "[3.66, 4.69, 4.29, 4.18, 4.35, 3.68]\n",
      "[4.27, 4.62, 4.47, 4.8, 4.81, 4.27]\n",
      "[4.55, 4.64, 4.64, 4.82, 4.91, 4.55]\n",
      "[3.45, 4.43, 3.33, 2.9, 3.65, 3.45]\n",
      "[4.0, 4.5, 5.0, 4.5, 4.5, 4.0]\n",
      "[3.47, 4.13, 3.83, 3.87, 4.02, 3.47]\n",
      "[4.66, 4.84, 4.8, 4.85, 4.91, 4.66]\n",
      "[4.8, 5.0, 4.8, 5.0, 5.0, 4.8]\n",
      "[2.94, 3.17, 3.32, 3.37, 3.57, 2.95]\n",
      "[3.22, 3.44, 3.56, 3.44, 3.67, 3.22]\n",
      "[3.5, 3.25, 4.0, 4.0, 4.25, 3.5]\n",
      "[4.17, 4.88, 4.73, 4.58, 4.77, 4.17]\n",
      "[4.73, 4.28, 4.63, 4.8, 4.89, 4.73]\n",
      "[4.22, 4.81, 4.47, 4.45, 4.66, 4.22]\n",
      "[3.5, 4.5, 4.0, 3.5, 4.5, 3.5]\n",
      "[3, 3, 3, 3, 3, 3]\n",
      "[4.17, 4.82, 4.55, 4.51, 4.81, 4.17]\n",
      "[3.74, 4.6, 4.08, 3.96, 4.18, 3.72]\n",
      "[4.0, 4.5, 4.0, 5.0, 4.0, 4.0]\n",
      "[3.89, 4.81, 4.31, 4.06, 4.59, 3.9]\n",
      "[3.05, 4.38, 3.28, 2.92, 3.73, 3.05]\n",
      "[4.41, 4.69, 4.22, 3.85, 4.3, 4.42]\n",
      "[3.56, 3.75, 3.31, 3.1, 3.36, 3.56]\n",
      "[3.89, 4.26, 4.01, 3.83, 3.96, 3.88]\n",
      "[4.25, 4.88, 4.49, 4.67, 4.67, 4.25]\n",
      "[3.87, 4.54, 4.13, 4.13, 4.31, 3.89]\n",
      "[4.39, 4.68, 4.75, 4.79, 4.77, 4.39]\n",
      "[4.5, 4.83, 4.5, 4.83, 4.83, 4.5]\n",
      "[3.0, 5.0, 5.0, 5.0, 5.0, 3.0]\n",
      "[4.04, 4.63, 3.81, 3.77, 4.04, 4.04]\n",
      "[4.19, 4.67, 4.42, 4.44, 4.5, 4.19]\n",
      "[3.75, 4.25, 4.25, 4.25, 4.5, 3.75]\n",
      "[4.09, 4.44, 4.47, 4.42, 4.62, 4.09]\n",
      "[3.83, 4.45, 3.94, 3.84, 4.11, 3.83]\n",
      "[3.9, 4.7, 4.2, 4.4, 4.7, 3.9]\n",
      "[3.93, 4.55, 3.9, 3.38, 4.1, 3.93]\n",
      "[3.06, 4.18, 3.02, 2.81, 3.68, 3.06]\n",
      "[3.58, 4.74, 3.61, 3.58, 4.19, 3.58]\n",
      "[3.67, 4.67, 4.33, 4.5, 4.33, 3.67]\n",
      "[[4.19, 4.9, 4.51, 4.55, 4.62, 4.21], [4.2, 4.55, 4.5, 4.51, 4.68, 4.2], [3.73, 4.72, 3.92, 3.8, 4.37, 3.73], [4.11, 4.49, 3.97, 3.77, 4.48, 4.11], [4.21, 4.87, 4.02, 3.92, 4.54, 4.21], [3.65, 3.38, 3.58, 3.57, 3.9, 3.65], [4.23, 4.67, 4.53, 4.54, 4.74, 4.23], [3.8, 4.63, 4.54, 4.35, 4.68, 3.8], [3.86, 4.43, 4.43, 4.57, 4.57, 3.86], [3.5, 4.0, 3.0, 3.75, 3.75, 3.5], [3.87, 4.91, 4.35, 4.35, 4.74, 3.87], [4.55, 4.88, 4.79, 4.73, 4.83, 4.57], [4.4, 5.0, 4.8, 4.6, 4.8, 4.4], [3.67, 3.67, 4.0, 4.0, 4.0, 3.67], [5.0, 5.0, 5.0, 4.0, 5.0, 5.0], [3.97, 3.64, 4.16, 4.19, 4.37, 3.98], [4.28, 4.82, 4.3, 4.33, 4.61, 4.28], [4.35, 4.91, 4.76, 4.75, 4.92, 4.36], [4.14, 4.95, 4.86, 4.72, 4.86, 4.14], [3, 3, 3, 3, 3, 3], [4.01, 3.44, 3.95, 4.1, 4.26, 4.04], [4.29, 4.67, 4.64, 4.67, 4.82, 4.29], [4.0, 5.0, 4.8, 4.8, 4.8, 4.0], [3.5, 3.5, 4.5, 3.5, 4.0, 3.5], [4.44, 4.79, 4.82, 4.71, 4.82, 4.44], [4.07, 3.79, 4.06, 3.98, 4.31, 4.07], [4.0, 4.0, 4.0, 3.5, 3.67, 4.0], [4.28, 4.84, 4.66, 4.69, 4.85, 4.28], [4.36, 4.87, 4.42, 4.34, 4.68, 4.36], [4.75, 5.0, 4.5, 4.25, 4.75, 4.75], [2.5, 2.5, 3.0, 3.0, 5.0, 2.5], [3.29, 4.44, 3.68, 2.85, 3.23, 3.29], [4.43, 4.26, 4.42, 4.63, 4.74, 4.43], [4.28, 4.9, 4.86, 4.81, 4.85, 4.28], [4.61, 4.87, 4.44, 4.88, 4.89, 4.62], [4.36, 4.74, 4.43, 4.29, 4.6, 4.36], [4.59, 4.72, 4.79, 4.82, 4.89, 4.59], [3.85, 3.58, 4.06, 4.09, 4.2, 3.85], [3.71, 4.5, 4.13, 4.04, 4.28, 3.73], [3.4, 5.0, 3.2, 3.6, 4.0, 3.4], [4.05, 4.42, 4.31, 4.39, 4.42, 4.07], [4.22, 4.44, 4.0, 4.33, 4.67, 4.22], [3.66, 4.69, 4.29, 4.18, 4.35, 3.68], [4.27, 4.62, 4.47, 4.8, 4.81, 4.27], [4.55, 4.64, 4.64, 4.82, 4.91, 4.55], [3.45, 4.43, 3.33, 2.9, 3.65, 3.45], [4.0, 4.5, 5.0, 4.5, 4.5, 4.0], [3.47, 4.13, 3.83, 3.87, 4.02, 3.47], [4.66, 4.84, 4.8, 4.85, 4.91, 4.66], [4.8, 5.0, 4.8, 5.0, 5.0, 4.8], [2.94, 3.17, 3.32, 3.37, 3.57, 2.95], [3.22, 3.44, 3.56, 3.44, 3.67, 3.22], [3.5, 3.25, 4.0, 4.0, 4.25, 3.5], [4.17, 4.88, 4.73, 4.58, 4.77, 4.17], [4.73, 4.28, 4.63, 4.8, 4.89, 4.73], [4.22, 4.81, 4.47, 4.45, 4.66, 4.22], [3.5, 4.5, 4.0, 3.5, 4.5, 3.5], [3, 3, 3, 3, 3, 3], [4.17, 4.82, 4.55, 4.51, 4.81, 4.17], [3.74, 4.6, 4.08, 3.96, 4.18, 3.72], [4.0, 4.5, 4.0, 5.0, 4.0, 4.0], [3.89, 4.81, 4.31, 4.06, 4.59, 3.9], [3.05, 4.38, 3.28, 2.92, 3.73, 3.05], [4.41, 4.69, 4.22, 3.85, 4.3, 4.42], [3.56, 3.75, 3.31, 3.1, 3.36, 3.56], [3.89, 4.26, 4.01, 3.83, 3.96, 3.88], [4.25, 4.88, 4.49, 4.67, 4.67, 4.25], [3.87, 4.54, 4.13, 4.13, 4.31, 3.89], [4.39, 4.68, 4.75, 4.79, 4.77, 4.39], [4.5, 4.83, 4.5, 4.83, 4.83, 4.5], [3.0, 5.0, 5.0, 5.0, 5.0, 3.0], [4.04, 4.63, 3.81, 3.77, 4.04, 4.04], [4.19, 4.67, 4.42, 4.44, 4.5, 4.19], [3.75, 4.25, 4.25, 4.25, 4.5, 3.75], [4.09, 4.44, 4.47, 4.42, 4.62, 4.09], [3.83, 4.45, 3.94, 3.84, 4.11, 3.83], [3.9, 4.7, 4.2, 4.4, 4.7, 3.9], [3.93, 4.55, 3.9, 3.38, 4.1, 3.93], [3.06, 4.18, 3.02, 2.81, 3.68, 3.06], [3.58, 4.74, 3.61, 3.58, 4.19, 3.58], [3.67, 4.67, 4.33, 4.5, 4.33, 3.67]]\n",
      "81\n"
     ]
    }
   ],
   "source": [
    "import urllib2\n",
    "import csv\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from bs4 import BeautifulSoup\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "\n",
    "url = []\n",
    "allVector = []\n",
    "with open('url.csv') as csvfile:\n",
    "    reader = csv.DictReader(csvfile)\n",
    "    for row in reader:\n",
    "        arr = str(row).split('/')\n",
    "        url.append(arr[1][:-2])\n",
    "        \n",
    "driver = webdriver.Firefox()\n",
    "for element in url:\n",
    "    value = 0\n",
    "    location = 0\n",
    "    s_quality = 0\n",
    "    rooms = 0\n",
    "    clean = 0\n",
    "    service = 0\n",
    "    total = 0\n",
    "    c = 0\n",
    "    link = 'https://www.tripadvisor.com/' + element\n",
    "    page = urllib2.urlopen(link).read()\n",
    "    soup = BeautifulSoup(page, \"lxml\")\n",
    "    current = soup.findAll('span', attrs = {'class':'pageNum current'})\n",
    "    my_next = soup.findAll('a', attrs = {'class':'nav next rndBtn ui_button primary taLnk'})\n",
    "    innerBubble = soup.findAll('div', attrs = {'class':'innerBubble'})\n",
    "    buff = BeautifulSoup(str(innerBubble), \"lxml\")\n",
    "    recommend = buff.findAll('ul', attrs = {'class':'recommend'})\n",
    "    \n",
    "    for e in recommend:\n",
    "        tmpSoup = BeautifulSoup(str(e), \"lxml\")\n",
    "        tmpRec = tmpSoup.findAll('li', attrs = {'class':'recommend-answer'})\n",
    "        if len(tmpRec) == 6:\n",
    "            total = total + 1\n",
    "            tmp0 = str(tmpRec[0])\n",
    "            html0 = BeautifulSoup(tmp0, \"lxml\")\n",
    "            current0 = html0.findAll('img', alt = True)\n",
    "            value = value + int(current0[0].get('alt')[:1])\n",
    "            \n",
    "            tmp1 = str(tmpRec[1])\n",
    "            html1 = BeautifulSoup(tmp1, \"lxml\")\n",
    "            current1 = html1.findAll('img', alt = True)\n",
    "            location = location + int(current1[0].get('alt')[:1])\n",
    "            \n",
    "            tmp2 = str(tmpRec[2])\n",
    "            html2 = BeautifulSoup(tmp2, \"lxml\")\n",
    "            current2 = html2.findAll('img', alt = True)\n",
    "            s_quality = s_quality + int(current2[0].get('alt')[:1])\n",
    "            \n",
    "            tmp3 = str(tmpRec[3])\n",
    "            html3 = BeautifulSoup(tmp3, \"lxml\")\n",
    "            current3 = html3.findAll('img', alt = True)\n",
    "            rooms = rooms + int(current3[0].get('alt')[:1])\n",
    "            \n",
    "            tmp4 = str(tmpRec[4])\n",
    "            html4 = BeautifulSoup(tmp4, \"lxml\")\n",
    "            current4 = html4.findAll('img', alt = True)\n",
    "            clean = clean + int(current4[0].get('alt')[:1])\n",
    "            \n",
    "            tmp5 = str(tmpRec[5])\n",
    "            html5 = BeautifulSoup(tmp5, \"lxml\")\n",
    "            current5 = html5.findAll('img', alt = True)\n",
    "            service = service + int(current5[0].get('alt')[:1])\n",
    "    url_link = link\n",
    "    html_page = urllib2.urlopen(url_link).read()\n",
    "    bs = BeautifulSoup(html_page, \"lxml\")\n",
    "    count = 0\n",
    "    next_page = bs.findAll('a', attrs = {'class':'nav next rndBtn ui_button primary taLnk'})\n",
    "    \n",
    "    template = url_link[:-16] + 'or'\n",
    "    html_page = urllib2.urlopen(url_link).read()\n",
    "    bs = BeautifulSoup(html_page, \"lxml\")\n",
    "    count = 0\n",
    "    next_div = bs.findAll('a', attrs = {'class':'nav next rndBtn ui_button primary taLnk'})\n",
    "    current = int(next_div[0].get('href')[-1:])\n",
    "    while count < 50:\n",
    "        url = template + str(current)\n",
    "        driver.get(url)\n",
    "    \n",
    "        page_source = driver.page_source\n",
    "        soup_2 = BeautifulSoup(page_source, \"lxml\")\n",
    "        rating = soup_2.findAll('ul', attrs = {'class':'recommend'})\n",
    "        for r in rating:\n",
    "            ratingSoup = BeautifulSoup(str(r), \"lxml\")\n",
    "            ratingRec = ratingSoup.findAll('li', attrs = {'class':'recommend-answer'})\n",
    "            \n",
    "            if len(ratingRec) == 6:\n",
    "                total = total + 1\n",
    "                rating_tmp0 = str(ratingRec[0])\n",
    "                rating_html0 = BeautifulSoup(rating_tmp0, \"lxml\")\n",
    "                rating_current0 = rating_html0.findAll('img', alt = True)\n",
    "                value = value + int(rating_current0[0].get('alt')[:1])\n",
    "                \n",
    "                rating_tmp1 = str(ratingRec[1])\n",
    "                rating_html1 = BeautifulSoup(rating_tmp1, \"lxml\")\n",
    "                rating_current1 = rating_html1.findAll('img', alt = True)\n",
    "                location = location + int(rating_current1[0].get('alt')[:1])\n",
    "                \n",
    "                rating_tmp2 = str(ratingRec[2])\n",
    "                rating_html2 = BeautifulSoup(rating_tmp2, \"lxml\")\n",
    "                rating_current2 = rating_html2.findAll('img', alt = True)\n",
    "                s_quality = s_quality + int(rating_current2[0].get('alt')[:1])\n",
    "                \n",
    "                rating_tmp3 = str(ratingRec[3])\n",
    "                rating_html3 = BeautifulSoup(rating_tmp3, \"lxml\")\n",
    "                rating_current3 = rating_html3.findAll('img', alt = True)\n",
    "                rooms = rooms + int(rating_current3[0].get('alt')[:1])\n",
    "                \n",
    "                rating_tmp4 = str(ratingRec[4])\n",
    "                rating_html4 = BeautifulSoup(rating_tmp4, \"lxml\")\n",
    "                rating_current4 = rating_html4.findAll('img', alt = True)\n",
    "                clean = clean + int(rating_current4[0].get('alt')[:1])\n",
    "                \n",
    "                rating_tmp5 = str(ratingRec[5])\n",
    "                rating_html5 = BeautifulSoup(rating_tmp5, \"lxml\")\n",
    "                rating_current5 = rating_html5.findAll('img', alt = True)\n",
    "                service = service + int(rating_current0[0].get('alt')[:1])\n",
    "        current = current + 6\n",
    "        count = count + 1\n",
    "    vector = [value, location, s_quality, rooms, clean, service]\n",
    "    #print vector\n",
    "    #print total\n",
    "    if(total == 0):\n",
    "        v = [3, 3, 3, 3, 3, 3]\n",
    "    else:\n",
    "        vc = [float(x) / total for x in vector]\n",
    "        v = [ round(elem, 2) for elem in vc ]\n",
    "    \n",
    "    print v\n",
    "    allVector.append(v)\n",
    "print allVector\n",
    "print len(allVector)\n",
    "\n",
    "data_x = pd.DataFrame(allVector)\n",
    "data_x.to_csv('clean_data.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "README: I extracted data and saved them in CSV file instead of printing out. Please take a look at the csv file in the GIT repository. The target.csv is the overall rating of each hotel. The clean_data.csv contains ratings of factors(clealiness, location, etc) that we want to use for further analysis, and each row of data is representing each hotel."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Task 2 (20 pts) **\n",
    "\n",
    "Now, we will use regression to analyze this information. First, we will fit a linear regression model that predicts the average rating. For example, for the hotel above, the average rating is\n",
    "\n",
    "$$ \\text{AVG_SCORE} = \\frac{1*31 + 2*33 + 3*98 + 4*504 + 5*1861}{2527}$$\n",
    "\n",
    "Use the model to analyze the important factors that decide the $\\text{AVG_SCORE}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Coefficients: \\n', array([ 14.60841166,   0.01640661,  -0.09695864,   0.46145172, -14.66996877]))\n",
      "Residual sum of squares: 0.34\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn import datasets, linear_model\n",
    "import pandas as pd\n",
    "import sklearn.cross_validation as cross_validation\n",
    "\n",
    "#value, location, sleep quality, rooms, cleanliness, service\n",
    "\n",
    "# Create linear regression object\n",
    "regr = linear_model.LinearRegression()\n",
    "y = pd.read_csv('target.csv')\n",
    "x = pd.read_csv('clean_data.csv')\n",
    "target = []\n",
    "training_set = []\n",
    "\n",
    "for index, row in y.iterrows():\n",
    "    target.append(row[1])\n",
    "\n",
    "target_y = [ round(elem, 2) for elem in target ]\n",
    "#row 4\n",
    "for index, row in x.iterrows():\n",
    "    tmp = [row[1], row[2], row[3], row[4], row[5], row[6]]\n",
    "    v = [ round(elem, 2) for elem in tmp ]\n",
    "    training_set.append(v)\n",
    "    \n",
    "ax = np.array(training_set)\n",
    "target_value = np.array(target_y)\n",
    "\n",
    "X_train, X_test, y_train, y_test = cross_validation.train_test_split(ax, target_value, test_size=0.4, random_state=0)\n",
    "\n",
    "regr.fit(X_train, y_train)\n",
    "print('Coefficients: \\n', regr.coef_)\n",
    "\n",
    "# The mean square error\n",
    "print(\"Residual sum of squares: %.2f\"\n",
    "      % np.mean((regr.predict(X_test) - y_test) ** 2))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Task 3 (30 pts) **\n",
    "\n",
    "Finally, we will use logistic regression to decide if a hotel is _excellent_ or not. We classify a hotel as _excellent_ if more than **60%** of its ratings are 5 stars. This is a binary attribute on which we can fit a logistic regression model. As before, use the model to analyze the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Code for setting the style of the notebook\n",
    "from IPython.core.display import HTML\n",
    "def css_styling():\n",
    "    styles = open(\"../../theme/custom.css\", \"r\").read()\n",
    "    return HTML(styles)\n",
    "css_styling()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
