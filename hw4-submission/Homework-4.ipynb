{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(In order to load the stylesheet of this notebook, execute the last code cell in this notebook)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recommender System for Amazon Electronics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this assignment, we will be working with the [Amazon dataset](http://cs-people.bu.edu/kzhao/teaching/amazon_reviews_Electronics.tar.gz). You will build a recommender system to make predictions related to reviews of Electronics products on Amazon.\n",
    "\n",
    "Your grades will be determined by your performance on the predictive tasks as well as a brief written report about the approaches you took.\n",
    "\n",
    "This assignment should be completed **individually**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**train.json** 1,000,000 reviews to be used for training. It is not necessary to use all reviews for training if doing so proves too computationally intensive. The fields in this file are:\n",
    "\n",
    "* **reviewerID** The ID of the reviewer. This is a hashed user identifier from Amazon.\n",
    "\n",
    "* **asin** The ID of the item. This is a hashed product identifier from Amazon.\n",
    "\n",
    "* **overall** The rating of reviewer gave the item.\n",
    "\n",
    "* **helpful** The helpfulness votes for the review. This has 2 subfields, 'nHelpful' and 'outOf'. The latter is the total number of votes this review received. The former is the number of those that considered the review to be helpful.\n",
    "\n",
    "* **reviewText** The text of the review.\n",
    "\n",
    "* **summary** The summary of the review.\n",
    "\n",
    "* **unixReviewTime** The time of the review in seconds since 1970."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**meta.json** Contains metadata of the items:\n",
    "\n",
    "* **asin** The ID of the item.\n",
    "\n",
    "* **categories** The category labels of the item being reviewed.\n",
    "\n",
    "* **price** The price of the item.\n",
    "\n",
    "* **brand** The brand of the item."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**pairs_Rating.txt** The pairs (reviewerID and asin) on which you are to predict ratings.\n",
    "\n",
    "**pairs_Purchase.txt** The pairs on which you are to predict whether a user purchased an item or not.\n",
    "\n",
    "**pairs_Helpful.txt** The pairs on which you are to predict helpfulness votes. A third column in this file is the total number of votes from which you should predict how many were helpful."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**helpful.json** The review data associated with the helpfulness prediction test set. The 'nHelpful' field has been removed from this data since that is the value you need to predict above. This data will only be of use for the helpfulness prediction task."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**baseline.py** A simple baseline for each task."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Tasks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Rating prediction** Predict people's star ratings as accurately as possible for those (reviewerID, asin) pairs in 'pairs_Rating.txt'. Accuracy will be measured in terms of the [root mean-squared error (RMSE)](http://www.kaggle.com/wiki/RootMeanSquaredError).\n",
    "\n",
    "**Purchase prediction** Predict given a (reviewerID, asin) pair from 'pairs_Purchase.txt' whether the user purchased the item (really, whether it was one of the items they reviewed). Accuracy will be measured in terms of the [categorization accuracy](http://www.kaggle.com/wiki/HammingLoss) (1 minus the Hamming loss).\n",
    "\n",
    "**Helpfulness prediction** Predic whether a user's review of an item will be considered helpful. The file 'pairs_Helpful.txt' contains (reviewerID, asin) pairs with a third column containing the number of votes the user's review of the item received. You must predict how many of them were helpful. Accuracy will be measured in terms of the total [absolute error](http://www.kaggle.com/wiki/AbsoluteError), i.e. you are penalized one according to the difference |nHelpful - prediction|, where 'nHelpful' is the number of helpful votes the review actually received, and 'prediction' is your prediction of this quantity.\n",
    "\n",
    "We set up competitions on Kaggle to keep track of your results compared to those of other members of the class. The leaderboard will show your results on half of the test data, but your ultimate score will depend on your predictions across the whole dataset.\n",
    "* Kaggle competition: [rating prediction](https://inclass.kaggle.com/c/cs591-hw3-rating-prediction3) click here to [join](https://kaggle.com/join/datascience16rating)\n",
    "* Kaggle competition: [purchase prediction](https://inclass.kaggle.com/c/cs591-hw3-purchase-prediction) click here to [join](https://kaggle.com/join/datascience16purchase)\n",
    "* Kaggle competition: [helpfulness prediction](https://inclass.kaggle.com/c/cs591-hw3-helpful-prediction) click here to [join](https://kaggle.com/join/datascience16helpful)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grading and Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You will be graded on the following aspects.\n",
    "\n",
    "* Your written report. This should describe the approaches you took to each of the 3 tasks. To obtain good performance, you should not need to invent new approaches (though you are more than welcome to) but rather you will be graded based on your decision to apply reasonable approaches to each of the given tasks. (**10pts** for each task)\n",
    "\n",
    "* Your ability to obtain a solution which outperforms the baselines on the unseen portion of the test data. Obtaining full marks requires a solution which is substantially better (at least several percent) than baseline performance. (**10pts** for each task)\n",
    "\n",
    "* Your ranking for each of the three tasks compared to other students in the class. (**5pts** for each task)\n",
    "\n",
    "* Obtain a solution which outperforms the baselines on the seen portion of the test data (the leaderboard). \n",
    "(**5pts** for each task)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baselines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Simple baselines have been provided for each of the 3 tasks. These are included in 'baselines.py' among the files above. These 3 baselines operate as follows:\n",
    "\n",
    "**Rating prediction** Returns the global average rating, or the user's average if you have seen them before in the training data.\n",
    "\n",
    "**Purchase prediction** Finds the most popular products that account for 50% of purchases in the training data. Return '1' whenever such a product is seen at test time, '0' otherwise.\n",
    "\n",
    "** Helpfulness prediction** Multiplies the number of votes by the global average helpfulness rate, or the user's rate if we saw this user in the training data.\n",
    "\n",
    "Running 'baseline.py' produces 3 files containing predicted outputs. Your submission files should have the same format."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset Citation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Image-based recommendations on styles and substitutes** J. McAuley, C. Targett, J. Shi, A. van den Hengel *SIGIR*, 2015\n",
    "\n",
    "**Inferring networks of substitutable and complementary products** J. McAuley, R. Pandey, J. Leskovec *Knowledge Discovery and Data Mining*, 2015"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0.Pre-process the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Basically I just trimmed some extraneous information from files and get rid of some signs like quotation marks, etc and created some one to one or one to many tables so I can do some aggregation or merge on those tables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "\n",
    "STOPWORDS_FD = 'stopwords'\n",
    "STOPWORDS = {}\n",
    "from collections import defaultdict\n",
    "\n",
    "# From Homework 2\n",
    "def get_words(filename):\n",
    "    words = {}\n",
    "    for line in open(filename):\n",
    "        word = line.rstrip()\n",
    "        words[word] = word\n",
    "    return words\n",
    "\n",
    "def readJson(f):\n",
    "    for l in open(f):\n",
    "        yield eval(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "arr = []\n",
    "for l in readJson('train.json'):\n",
    "    tmp = [l['reviewerID'],l['asin'],l['overall']]\n",
    "    arr.append(tmp)\n",
    "\n",
    "df = pd.DataFrame(arr)\n",
    "df.to_csv('reviewerID-asin.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('reviewerID-asin.csv')\n",
    "users = []\n",
    "items = []\n",
    "for index,item in df.iterrows():\n",
    "    s = str(item[1])\n",
    "    i = str(item[2])\n",
    "    users.append(s)\n",
    "    items.append(i)\n",
    "    \n",
    "users = list(set(users))\n",
    "items = list(set(items))\n",
    "\n",
    "df1 = pd.DataFrame(users)\n",
    "df2 = pd.DataFrame(items)\n",
    "df1.to_csv('train_users.csv')\n",
    "df2.to_csv('train_items.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_users = pd.read_csv('train_users.csv')\n",
    "train_items = pd.read_csv('train_items.csv')\n",
    "overall_rating = pd.read_csv('reviewerID-asin.csv')\n",
    "\n",
    "user_avg_rating = {}\n",
    "train_items.columns = ['index','item']\n",
    "\n",
    "overall_rating.columns = ['index','user_id', 'item', 'rating']\n",
    "\n",
    "group_by_user_avg_rating = overall_rating.groupby(['user_id'])['rating'].mean()\n",
    "\n",
    "test = pd.DataFrame(group_by_user_avg_rating)\n",
    "\n",
    "item_total = 0\n",
    "item_count = 0\n",
    "user_total = 0\n",
    "user_count = 0\n",
    "\n",
    "user_avg_rating = {}# average rating of a user has given\n",
    "for index, item in test.iterrows():\n",
    "    user_count = user_count + 1\n",
    "    _id = str(index)\n",
    "    rating = item\n",
    "    user_total = user_total + float(rating)\n",
    "    user_avg_rating[_id] = float(rating)\n",
    "\n",
    "group_by_item_avg_rating = overall_rating.groupby(['item'])['rating'].mean()\n",
    "test2 = pd.DataFrame(group_by_item_avg_rating)\n",
    "test2.to_csv('item_avg_rating.csv')\n",
    "\n",
    "item_avg_rating = {}# average rating of each item\n",
    "for index, item in test2.iterrows():\n",
    "    item_count = item_count + 1\n",
    "    item_id = str(index)[4:]\n",
    "    rating = float(item)\n",
    "    item_avg_rating[item_id] = rating\n",
    "    item_total = item_total + rating\n",
    "    \n",
    "#all_item_avg_score = 3.789\n",
    "all_user_avg_score = 3.78\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test = []\n",
    "for l in open(\"pairs_Rating.txt\"):\n",
    "    u,i = l.strip().split('-')\n",
    "    test.append(i)\n",
    "\n",
    "test_set = []\n",
    "for index, item in test2.iterrows():\n",
    "    item_id = str(index)\n",
    "    test_set.append(item_id)\n",
    "\n",
    "test_set = list(set(test_set))\n",
    "test = list(set(test))\n",
    "\n",
    "all_existing_items = pd.DataFrame(test_set)\n",
    "all_existing_items.columns = ['item']\n",
    "\n",
    "allItems = pd.DataFrame.from_csv(\"test.csv\")\n",
    "allItems.columns = ['item','types','price']\n",
    "allItems['item'] = allItems['item'].astype(str)\n",
    "\n",
    "result = all_existing_items.merge(allItems, left_on='item', right_on='item', how='inner')\n",
    "result.to_csv('all_existing_items_information.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "item_info = pd.read_csv('all_existing_items_information.csv')\n",
    "item_info.columns = ['index','item','types','price']\n",
    "cate_price = item_info.groupby(['types'])['price'].mean()\n",
    "cate_price.to_csv('cate_price.csv')\n",
    "\n",
    "item_price = item_info.groupby(['item'])['price'].mean()\n",
    "#item_price[item_price == 0.0] = 76.55\n",
    "item_price.to_csv('item_price.csv')\n",
    "\n",
    "item_info = pd.read_csv('all_existing_items_information.csv')\n",
    "item_info.columns = ['index','item','types','price']\n",
    "cate_price = pd.read_csv('cate_price.csv')\n",
    "cate_price.columns = ['types', 'prices']\n",
    "\n",
    "item_cate_price = item_info.merge(cate_price, left_on='types', right_on='types', how='inner')\n",
    "item_cate_price.to_csv('item_cate_price.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "76.5536098567\n"
     ]
    }
   ],
   "source": [
    "item_price_non_zeros = pd.read_csv('item_price.csv')\n",
    "item_price_non_zeros.columns = ['item','avg_price']\n",
    "df = item_price_non_zeros[(item_price_non_zeros != 0.0).all(1)]\n",
    "df.to_csv('item_price_non_zeros.csv')\n",
    "print df['avg_price'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000000\n",
      "1000000\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "uer_helpfulness = []\n",
    "user_wordcount = []\n",
    "current_wordcount = []\n",
    "trainning_helpfulness = []\n",
    "for l in readJson('train.json'):\n",
    "    helpful = float(l[\"helpful\"][\"nHelpful\"])\n",
    "    outOf = float(l[\"helpful\"][\"outOf\"])\n",
    "    rate = helpful / outOf\n",
    "    line = l[\"reviewText\"]\n",
    "    user =  l[\"reviewerID\"]\n",
    "    count = len(re.findall(r'\\w+', line))\n",
    "    tmp1 = [user, rate]\n",
    "    uer_helpfulness.append(tmp1)\n",
    "    tmp2 = [user, count]\n",
    "    user_wordcount.append(tmp2)\n",
    "    current_wordcount.append(count)\n",
    "    trainning_helpfulness.append(rate)\n",
    "\n",
    "uer_helpfulness_df = pd.DataFrame(uer_helpfulness)\n",
    "uer_helpfulness_df.columns = ['user', 'uer_helpfulness']\n",
    "a = uer_helpfulness_df.groupby(['user'])['uer_helpfulness'].mean()\n",
    "a.to_csv('user_avg_helpfulness.txt')\n",
    "\n",
    "user_wordcount_df = pd.DataFrame(user_wordcount)\n",
    "user_wordcount_df.columns = ['user', 'user_wordcount']\n",
    "b = user_wordcount_df.groupby(['user'])['user_wordcount'].mean()\n",
    "b.to_csv('user_avg_wordcount.txt')\n",
    "\n",
    "current_wordcount_df = pd.DataFrame(current_wordcount)\n",
    "current_wordcount_df.to_csv(\"current_wordcount.txt\")\n",
    "\n",
    "trainning_helpfulness_df = pd.DataFrame(trainning_helpfulness)\n",
    "trainning_helpfulness_df.to_csv(\"trainning_helpfulness.txt\")\n",
    "\n",
    "print len(trainning_helpfulness_df)\n",
    "print len(current_wordcount_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100000\n",
      "100000\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "user_item_helpful = []\n",
    "helpful = []\n",
    "for l in open(\"pairs_Helpful.txt\"):\n",
    "    u,i,k = l.strip().split('-')\n",
    "    if l.startswith(\"reviewerID\"):\n",
    "        continue\n",
    "    tmp = [u, i]\n",
    "    user_item_helpful.append(tmp)\n",
    "    helpful.append(k)\n",
    "\n",
    "user_item_helpful_df = pd.DataFrame(user_item_helpful)\n",
    "user_item_helpful_df.to_csv(\"user_item_helpful.txt\")\n",
    "\n",
    "helpful_df = pd.DataFrame(helpful)\n",
    "helpful_df.to_csv(\"helpful.txt\")\n",
    "\n",
    "print len(user_item_helpful_df)\n",
    "print len(helpful_df)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Rating Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I used linear regression on average rating a user has given, average rating an item has received and average price of an item to predict the overall rating of a user-item pair."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100000\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import pandas as pd\n",
    "import json\n",
    "import numpy as np\n",
    "from sklearn import linear_model\n",
    "from sklearn.linear_model import BayesianRidge, LinearRegression\n",
    "from sklearn import svm\n",
    "from sklearn import tree\n",
    "from sklearn import preprocessing\n",
    "from sklearn import ensemble\n",
    "from sklearn import neighbors\n",
    "from sklearn.ensemble import ExtraTreesRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "reviewerID_asin = pd.read_csv('reviewerID-asin.csv')\n",
    "reviewerID_asin.columns = ['index','user','item','rate']\n",
    "\n",
    "item_avg_rating = pd.read_csv('item_avg_rating.csv')\n",
    "item_avg_rating.columns = ['item','avg_rate']\n",
    "\n",
    "item_price = pd.read_csv('item_price.csv')\n",
    "item_price.columns = ['item','avg_price']\n",
    "\n",
    "user_rate = pd.read_csv('group_by_user_avg_rating.csv')\n",
    "user_rate.columns = ['user','give_rate']\n",
    "\n",
    "item_cate_price = pd.read_csv('item_cate_price.csv')\n",
    "#item_cate_price.columns = ['item','cat','cat_price']\n",
    "item_cate_price.drop(['price', 'index'], axis=1, inplace=True)\n",
    "\n",
    "item_cate_price.columns = ['index', 'item','cat','cat_price']\n",
    "\n",
    "tmp1 = reviewerID_asin.merge(item_avg_rating, left_on='item', right_on='item', how='inner')\n",
    "tmp2 = tmp1.merge(item_price, left_on='item', right_on='item', how='inner')\n",
    "tmp3 = tmp2.merge(user_rate, left_on='user', right_on='user', how='inner')\n",
    "tmp4 = tmp3.merge(item_cate_price, left_on='item', right_on='item', how='inner')\n",
    "tmp4.drop(['index_y', 'index_x'], axis=1, inplace=True)\n",
    "\n",
    "X = tmp4.copy()\n",
    "X.drop(['user', 'item','cat','rate','cat_price'], axis=1, inplace=True) #','cat_price'',\n",
    "\n",
    "y = tmp4.copy()\n",
    "y.drop(['user', 'item','cat','avg_price','give_rate', 'cat_price', 'avg_rate'], axis=1, inplace=True)\n",
    "\n",
    "\n",
    "train_X = X.as_matrix()\n",
    "train_Y = y.as_matrix()\n",
    "\n",
    "my_x = np.array(train_X)\n",
    "my_y = np.array(train_Y)\n",
    "# Train the model using the training sets\n",
    "X_normalized = preprocessing.normalize(my_x, norm='l2')\n",
    "\n",
    "regr = linear_model.LinearRegression()\n",
    "regr.fit(my_x, my_y)\n",
    "\n",
    "testing = []\n",
    "for l in open(\"pairs_Rating.txt\"):\n",
    "    u,i = l.strip().split('-')\n",
    "    tmp = [u,i]\n",
    "    testing.append(tmp)\n",
    "    \n",
    "user_item = pd.DataFrame(testing)\n",
    "user_item = user_item[1:]\n",
    "user_item.columns = ['user', 'item']\n",
    "\n",
    "tp1 = user_item.merge(item_avg_rating, left_on='item', right_on='item', how='left')\n",
    "tp2 = tp1.merge(item_price, left_on='item', right_on='item', how='left')\n",
    "tp3 = tp2.merge(user_rate, left_on='user', right_on='user', how='left')\n",
    "tp4 = tp3.merge(item_cate_price, left_on='item', right_on='item', how='left')\n",
    "tp4.drop(['user', 'item','cat','index','cat_price'], axis=1, inplace=True) #,'cat_price' ,'avg_rate'\n",
    "\n",
    "\n",
    "tp4.fillna(3.78, inplace=True)\n",
    "testing_x = tp4.as_matrix()\n",
    "X_normalized_testing = preprocessing.normalize(testing_x, norm='l2')\n",
    "#h2 = est.predict(X_normalized_testing)\n",
    "#h3 = clf.predict(X_normalized_testing)\n",
    "h2 = regr.predict(testing_x)\n",
    "print len(h2)\n",
    "\n",
    "predictions = open(\"predictions_Rating.txt\", 'w')\n",
    "count = 0\n",
    "for l in open(\"pairs_Rating.txt\"):\n",
    "    if l.startswith(\"reviewerID\"):\n",
    "        #header\n",
    "        predictions.write(l)\n",
    "        continue\n",
    "    u,i = l.strip().split('-')\n",
    "    rate = round(h2[count],4)\n",
    "    ans = 0.4 * rate + 0.6 * 3.8375\n",
    "    predictions.write(u + '-' + i + ',' + str(ans) + '\\n')\n",
    "    count = count + 1\n",
    "predictions.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# 2.Purchase prediction\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this part, I used simple user collaberative filtering. I look through every user's purcahse history and find out what kind of items they like most or they gave highest rate so that I can compare a future item with exsiting user pereferences. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "import pandas as pd\n",
    "import json\n",
    "import numpy as np\n",
    "reviewerID_asin = pd.read_csv('reviewerID-asin.csv')\n",
    "reviewerID_asin.columns = ['index','user', 'item', 'score']\n",
    "purchase_times_user = reviewerID_asin.groupby(['user'])['user'].count()\n",
    "purchase_times_user.to_csv('purchase_times_user.csv')\n",
    "\n",
    "purchase_times_item = reviewerID_asin.groupby(['item'])['item'].count()\n",
    "purchase_times_item.to_csv('purchase_times_item.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "import pandas as pd\n",
    "import json\n",
    "import numpy as np\n",
    "from sklearn import linear_model\n",
    "from sklearn import svm\n",
    "\n",
    "reviewerID_asin = pd.read_csv('reviewerID-asin.csv')\n",
    "reviewerID_asin.columns = ['index','user', 'item', 'score']\n",
    "\n",
    "item_avg_rating = pd.read_csv('item_avg_rating.csv')\n",
    "item_avg_rating.columns = ['item','avg_rate']\n",
    "\n",
    "item_price = pd.read_csv('item_price.csv')\n",
    "item_price.columns = ['item','avg_price']\n",
    "\n",
    "user_rate = pd.read_csv('group_by_user_avg_rating.csv')\n",
    "user_rate.columns = ['user','give_rate']\n",
    "\n",
    "purchase_times_item = pd.read_csv('purchase_times_item.csv')\n",
    "purchase_times_item.columns = ['item', 'item_times']\n",
    "\n",
    "purchase_times_user = pd.read_csv('purchase_times_user.csv')\n",
    "purchase_times_user.columns = ['user', 'user_times']\n",
    "\n",
    "tmp1 = reviewerID_asin.merge(item_avg_rating, left_on='item', right_on='item', how='left')\n",
    "tmp2 = tmp1.merge(item_price, left_on='item', right_on='item', how='left')\n",
    "tmp3 = tmp2.merge(user_rate, left_on='user', right_on='user', how='left')\n",
    "tmp4 = tmp3.merge(purchase_times_user, left_on='user', right_on='user', how='left')\n",
    "tmp5 = tmp4.merge(purchase_times_item, left_on='item', right_on='item', how='left')\n",
    "user_basic_info = tmp5.copy()\n",
    "\n",
    "a = user_basic_info.groupby(['user'])['avg_rate'].mean()\n",
    "a.to_csv('user-item_avg_rate.txt')\n",
    "\n",
    "b = user_basic_info.groupby(['user'])['avg_price'].mean()\n",
    "b.to_csv('user-item_avg_price.txt')\n",
    "\n",
    "c = user_basic_info.groupby(['user'])['item_times'].mean()\n",
    "c.to_csv('user-item_times.txt')\n",
    "\n",
    "d = user_basic_info.groupby(['item'])['avg_rate'].mean()\n",
    "d.to_csv('item_avg_rate.txt')\n",
    "\n",
    "e = user_basic_info.groupby(['item'])['item_times'].mean()\n",
    "e.to_csv('item_avg_times.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.78936422692\n",
      "5.84164407889\n",
      "3.81509771505\n",
      "74.2812708206\n"
     ]
    }
   ],
   "source": [
    "item_avg_rate = pd.read_csv('item_avg_rate.txt')\n",
    "item_avg_times = pd.read_csv('item_avg_times.txt')\n",
    "item_avg_rate.columns = ['item', 'rate']\n",
    "item_avg_times.columns = ['item', 'times']\n",
    "print item_avg_rate['rate'].mean()\n",
    "print item_avg_times['times'].mean()\n",
    "\n",
    "t1 = item_avg_rate.merge(item_avg_times, left_on='item', right_on='item', how='left')\n",
    "\n",
    "user_item_avg_rate = pd.read_csv('user-item_avg_rate.txt')\n",
    "#user_item_avg_price = pd.read_csv('user-item_avg_price.txt')\n",
    "user_item_times = pd.read_csv('user-item_times.txt')\n",
    "user_item_avg_rate.columns = ['user', 'item_avg_rate']\n",
    "#user_item_avg_price.columns = ['user', 'item_avg_price']\n",
    "user_item_times.columns = ['user', 'item_times']\n",
    "print user_item_avg_rate['item_avg_rate'].mean()\n",
    "print user_item_times['item_times'].mean()\n",
    "\n",
    "user_preference = {}\n",
    "item_dict = {}\n",
    "tmp1 = user_item_avg_rate.merge(user_item_times, left_on='user', right_on='user', how='left')\n",
    "#tmp2 = tmp1.merge(user_item_times, left_on='user', right_on='user', how='left')\n",
    "\n",
    "for index, item in t1.iterrows():\n",
    "    item_dict[str(item[0])] = [round(float(item[1]),3), float(item[2])]\n",
    "\n",
    "for index, item in tmp1.iterrows():\n",
    "    user_preference[str(item[0])] = [round(float(item[1]),3), float(item[2])]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100000\n"
     ]
    }
   ],
   "source": [
    "from sklearn import preprocessing\n",
    "from scipy import spatial\n",
    "ct = 0\n",
    "predictions = open(\"predictions_Purchase.txt\", 'w')\n",
    "for l in open(\"pairs_Purchase.txt\"):\n",
    "    if l.startswith(\"reviewerID\"):\n",
    "        predictions.write(l)\n",
    "        continue\n",
    "    u,i = l.strip().split('-')\n",
    "    if u not in user_preference:\n",
    "        current_user_preference = [3.815, 74.281]\n",
    "    else:\n",
    "        current_user_preference = user_preference[u]\n",
    "    if i not in item_dict:\n",
    "        current_item_info = [1,1]\n",
    "    else:\n",
    "        current_item_info = item_dict[i]\n",
    "   \n",
    "    if current_item_info[0] >= current_user_preference[0] * 0.55 and current_item_info[1] >= current_user_preference[1] * 0.015:\n",
    "        predictions.write(u + '-' + i + \",1\\n\")\n",
    "    else:\n",
    "        predictions.write(u + '-' + i + \",0\\n\")\n",
    "    ct = ct + 1\n",
    "predictions.close()\n",
    "print ct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3 Helpfulness prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://inclass.kaggle.com/c/cs591-hw3-helpful-prediction2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, avg_rate             2.000000\n",
      "give_rate            2.857143\n",
      "item_times           1.000000\n",
      "avg_helpfulness      0.625000\n",
      "avg_wordcount      319.857143\n",
      "Name: 0, dtype: float64)\n",
      "(0, avg_rate             2.75000\n",
      "give_rate            2.50000\n",
      "item_times           4.00000\n",
      "avg_helpfulness      0.46875\n",
      "avg_wordcount      131.50000\n",
      "Name: 0, dtype: float64)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\n# The mean square error\\nprint(\"Residual sum of squares: %.2f\"\\n      % np.mean((regr.predict(X_test) - y_test) ** 2))\\n# Explained variance score: 1 is perfect prediction\\nprint(\\'Variance score: %.2f\\' % regr.score(X_test, y_test))\\n\\n# The coefficients\\nprint(\\'Coefficients: \\n\\', regr.coef_)\\n\\nmodel = sm.OLS(train_Y, train_X)\\nresults = model.fit()\\nprint(results.summary())\\n\\n#avg_rate give_rate item_times avg_helpfulness avg_wordcount\\n'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import csv\n",
    "import pandas as pd\n",
    "import json\n",
    "import numpy as np\n",
    "from sklearn import linear_model\n",
    "from sklearn import svm\n",
    "import statsmodels.api as sm\n",
    "import sklearn.cross_validation as cross_validation\n",
    "\n",
    "item_avg_rating = pd.read_csv('item_avg_rating.csv')\n",
    "item_avg_rating.columns = ['item','avg_rate']\n",
    "\n",
    "user_rate = pd.read_csv('group_by_user_avg_rating.csv')\n",
    "user_rate.columns = ['user','give_rate']\n",
    "\n",
    "purchase_times_item = pd.read_csv('purchase_times_item.csv')\n",
    "purchase_times_item.columns = ['item', 'item_times']\n",
    "\n",
    "purchase_times_user = pd.read_csv('purchase_times_user.csv')\n",
    "purchase_times_user.columns = ['user', 'user_times']\n",
    "\n",
    "reviewerID_asin = pd.read_csv('reviewerID-asin.csv')\n",
    "reviewerID_asin.columns = ['index','user', 'item', 'score']\n",
    "reviewerID_asin.drop(['score'], axis=1, inplace=True)\n",
    "\n",
    "user_avg_helpfulness = pd.read_csv('user_avg_helpfulness.txt')\n",
    "user_avg_helpfulness.columns = ['user','avg_helpfulness']\n",
    "\n",
    "user_avg_wordcount = pd.read_csv('user_avg_wordcount.txt')\n",
    "user_avg_wordcount.columns = ['user','avg_wordcount']\n",
    "\n",
    "tmp1 = reviewerID_asin.merge(item_avg_rating, left_on='item', right_on='item', how='left')\n",
    "tmp2 = tmp1.merge(user_rate, left_on='user', right_on='user', how='left')\n",
    "tmp3 = tmp2.merge(purchase_times_item, left_on='item', right_on='item', how='left')\n",
    "tmp4 = tmp3.merge(purchase_times_user, left_on='user', right_on='user', how='left')\n",
    "tmp5 = tmp4.merge(user_avg_helpfulness, left_on='user', right_on='user', how='left')\n",
    "tmp6 = tmp5.merge(user_avg_wordcount, left_on='user', right_on='user', how='left')\n",
    "\n",
    "target_pd = pd.read_csv(\"trainning_helpfulness.txt\")\n",
    "target_pd.columns = ['index','rate']\n",
    "tmp6.drop(['user', 'item', 'index','user_times'], axis=1, inplace=True) #,'give_rate', 'item_times','current_word_count'\n",
    "target_pd.drop(['index'], axis=1, inplace=True)\n",
    "\n",
    "c = 0\n",
    "for test in tmp6.iterrows():\n",
    "    print test\n",
    "    break\n",
    "\n",
    "\n",
    "tmp6.fillna(0, inplace=True)\n",
    "train_X = tmp6.as_matrix()\n",
    "train_Y = target_pd.as_matrix()\n",
    "\n",
    "regr = linear_model.LinearRegression()\n",
    "regr.fit(train_X, train_Y)\n",
    "\n",
    "user_item_helpful_df = pd.read_csv(\"user_item_helpful.txt\")\n",
    "helpful_df = pd.read_csv(\"helpful.txt\")\n",
    "user_item_helpful_df.columns = [\"index\", \"user\", \"item\"]\n",
    "user_item_helpful_df.drop(['index'], axis=1, inplace=True)\n",
    "\n",
    "t1 = user_item_helpful_df.merge(item_avg_rating, left_on='item', right_on='item', how='left')\n",
    "t2 = t1.merge(user_rate, left_on='user', right_on='user', how='left')\n",
    "t3 = t2.merge(purchase_times_item, left_on='item', right_on='item', how='left')\n",
    "t4 = t3.merge(user_avg_helpfulness, left_on='user', right_on='user', how='left')\n",
    "t5 = t4.merge(user_avg_wordcount, left_on='user', right_on='user', how='left')\n",
    "t5.drop(['user', 'item'], axis=1, inplace=True)\n",
    "for test in t5.iterrows():\n",
    "    print test\n",
    "    break\n",
    "\n",
    "\n",
    "'''\n",
    "# The mean square error\n",
    "print(\"Residual sum of squares: %.2f\"\n",
    "      % np.mean((regr.predict(X_test) - y_test) ** 2))\n",
    "# Explained variance score: 1 is perfect prediction\n",
    "print('Variance score: %.2f' % regr.score(X_test, y_test))\n",
    "\n",
    "# The coefficients\n",
    "print('Coefficients: \\n', regr.coef_)\n",
    "\n",
    "model = sm.OLS(train_Y, train_X)\n",
    "results = model.fit()\n",
    "print(results.summary())\n",
    "\n",
    "#avg_rate give_rate item_times avg_helpfulness avg_wordcount\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "allHelpful = []\n",
    "userHelpful = defaultdict(list)\n",
    "\n",
    "for l in readJson('train.json'):\n",
    "    user,item = l['reviewerID'],l['asin']\n",
    "    allHelpful.append(l['helpful'])\n",
    "    userHelpful[user].append(l['helpful'])\n",
    "\n",
    "averageRate = sum([x['nHelpful'] for x in allHelpful]) * 1.0 / sum([x['outOf'] for x in allHelpful])\n",
    "userRate = {}\n",
    "for u in userHelpful:\n",
    "    userRate[u] = sum([x['nHelpful'] for x in userHelpful[u]]) * 1.0 / sum([x['outOf'] for x in userHelpful[u]])\n",
    "\n",
    "predictions = open(\"predictions_Helpful.txt\", 'w')\n",
    "for l in open(\"pairs_Helpful.txt\"):\n",
    "    if l.startswith(\"reviewerID\"):\n",
    "        predictions.write(l)\n",
    "        continue\n",
    "    u,i,outOf = l.strip().split('-')\n",
    "    outOf = int(outOf)\n",
    "    if u in userRate:\n",
    "        predictions.write(u + '-' + i + '-' + str(outOf) + ',' + str(outOf*userRate[u]) + '\\n')\n",
    "    else:\n",
    "        predictions.write(u + '-' + i + '-' + str(outOf) + ',' + str(outOf*averageRate) + '\\n')\n",
    "predictions.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Code for setting the style of the notebook\n",
    "from IPython.core.display import HTML\n",
    "def css_styling():\n",
    "    styles = open(\"../theme/custom.css\", \"r\").read()\n",
    "    return HTML(styles)\n",
    "css_styling()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
