{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(In order to load the stylesheet of this notebook, execute the last code cell in this notebook)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stack Overflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this assignment, we will look at some posts on Stack Overflow during the year of 2015 and measure the similarity of users by looking at the types of questions they answer. We will also analyze the creation dates of questions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 0. Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we start working on the notebook, let's make sure that everything is setup properly. You should have downloaded and installed\n",
    "* [Anaconda](https://store.continuum.io/cshop/anaconda/)\n",
    "* [Git](http://git-scm.com/downloads)\n",
    "\n",
    "If you are working from the undergraduate lab (on a linux machine) these are both installed, but you need to follow the instructions [from here](https://github.com/datascience16/lectures/blob/master/Lecture2/Getting-Started.ipynb).\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1. Getting the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's make a sample request to retrieve the questions posted on Stack Exchange on the first day of 2015. Documentation of the Stack Exchange API can be found [here](https://api.stackexchange.com/docs)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Response [200]>\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "start_time = 1420070400 # 01-01-2015 at 00:00:00\n",
    "end_time   = 1420156800 # 01-02-2015 at 00:00:00\n",
    "\n",
    "response = requests.get(\"https://api.stackexchange.com/2.2/questions?pagesize=100\" +\n",
    "                        \"&fromdate=\" + str(start_time) + \"&todate=\" + str(end_time) +\n",
    "                        \"&order=asc&sort=creation&site=stackoverflow\")\n",
    "print response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All dates in the Stack Exchange API are in [unix epoch time](https://en.wikipedia.org/wiki/Unix_time). The format for the request string is specified [here](https://api.stackexchange.com/docs/questions)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can try to print the response that Stack Exchange returns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print response.text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is not possible to read the raw response. Instead, we need to decode the raw response as JSON and use the `json` library to print it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "print json.dumps(response.json(), indent=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can easily see that the response consists of a list of question items. For each of these items, we get information about its attributes such as its `creation_date`, `answer_count`, `owner`, `title`, etc.\n",
    "\n",
    "Notice that has_more is true. To get more items, we can [request the next page](https://api.stackexchange.com/docs/paging)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2. Parsing the responses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section, we practice some of the basic Python tools that we learned in class and the powerful string handling methods that Python offers. Our goal is to be able to pick the interesting parts of the response and transform them in a format that will be useful to us."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First let's isolate the creation_date in the response. Fill in the rest of the ```print_creation_dates_json()``` function that reads the response and prints the creation dates. Notice that a JSON object is basically a dictionary. **(5 pts)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import time, datetime\n",
    "def print_creation_dates_json(response):\n",
    "    data = json.loads(response.text)\n",
    "    items = data['items']\n",
    "    for element in items:\n",
    "        #print element['creation_date']\n",
    "        print datetime.datetime.utcfromtimestamp(int(element['creation_date']))\n",
    "    \"\"\"\n",
    "    Prints the creation_date of all the questions in the response.\n",
    "    \n",
    "    Parameters:\n",
    "        response: Response object\n",
    "    \"\"\"\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write the code that calls the ```print_creation_dates_json()``` function to print out all the creation dates of questions posted on the first day in 2015. Please be aware of Stack Exchange's [rate limit](https://api.stackexchange.com/docs/throttle). **(5 pts)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'print_creation_dates_json' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-27-51aa11f3f653>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m                         \u001b[0;34m\"&fromdate=\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstart_time\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"&todate=\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mend_time\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m                         \"&order=asc&sort=creation&site=stackoverflow\")\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mprint_creation_dates_json\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'print_creation_dates_json' is not defined"
     ]
    }
   ],
   "source": [
    "#1420088400\n",
    "import requests\n",
    "import json\n",
    "start_time = 1420070400 # 01-01-2015 at 00:00:00\n",
    "end_time   = 1420156800 # 01-02-2015 at 00:00:00\n",
    "\n",
    "response = requests.get(\"https://api.stackexchange.com/2.2/questions?pagesize=100\" +\n",
    "                        \"&fromdate=\" + str(start_time) + \"&todate=\" + str(end_time) +\n",
    "                        \"&order=asc&sort=creation&site=stackoverflow\")\n",
    "print_creation_dates_json(response)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Due to time constraints, we have downloaded the [data dump](http://cs-people.bu.edu/kzhao/teaching/stackoverflow-posts-2015.tar.gz) for Stack Overflow's posts in 2015. Note that this file is 10GB. If you don't have space on your computer, you can download it into `/scratch` on one of the machines in the undergrad lab or you can download it onto a USB. You may also want to work with a subset of this data at first, but your solution should be efficient enough to work with the whole dataset. For example, if you call `read()` on this file, you will get a `MemoryError`.\n",
    "\n",
    "Write a function to parse out the questions posted in 2015. These are posts with `PostTypeId=1`. Make a `pandas DataFrame` with 3 columns: `Id`, `CreationDate`, `OwnerUserId`, and the first tag in `Tags`. Save the `DataFrame` to a file named `question_dataframe.csv` using `to_csv()`. **(10 pts)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import xml.etree.ElementTree as etree\n",
    "\n",
    "def fetchData():\n",
    "    df = pd.DataFrame(columns=('Id', 'CreationDate', 'OwnerUserId', 'Tag'))\n",
    "    rows_list = []\n",
    "    count = 0;\n",
    "    for event, elem in etree.iterparse('stackoverflow-posts-2015.xml'):\n",
    "        if(elem.attrib['PostTypeId'] == '1'):\n",
    "            tag = elem.attrib['Tags']\n",
    "            tag = tag.split('>')[0][1:]\n",
    "            Id = elem.attrib['Id']\n",
    "            date = elem.attrib['CreationDate']\n",
    "            try:\n",
    "                owner = elem.attrib['OwnerUserId']\n",
    "            except:\n",
    "                owner = elem.attrib['OwnerDisplayName']\n",
    "            df.loc[0] = [Id, date, owner,tag]  # adding a row\n",
    "            df.index = df.index + 1\n",
    "            count = count + 1\n",
    "        elem.clear()\n",
    "        if(count == 1000):\n",
    "            break\n",
    "    df = df.reset_index(drop=True)\n",
    "    df.to_csv('question_dataframe_sample.csv')\n",
    "        \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Unnamed: 0        Id             CreationDate OwnerUserId            Tag\n",
      "0             0  27727385  2015-01-01T00:00:58.253     3210431            php\n",
      "1             1  27727388  2015-01-01T00:01:43.673      868779     apache-pig\n",
      "2             2  27727391  2015-01-01T00:02:32.123     4372672            ios\n",
      "3             3  27727393  2015-01-01T00:02:57.983     2482149     sql-server\n",
      "4             4  27727394  2015-01-01T00:03:31.337     4263870            php\n",
      "5             5  27727396  2015-01-01T00:04:01.407     4409381        android\n",
      "6             6  27727406  2015-01-01T00:05:03.773      875317             c#\n",
      "7             7  27727407  2015-01-01T00:05:27.167      821742           java\n",
      "8             8  27727408  2015-01-01T00:05:34.733     2595033             c#\n",
      "9             9  27727409  2015-01-01T00:06:17.720     1815395         apache\n",
      "10           10  27727410  2015-01-01T00:06:41.067      541091          mysql\n",
      "11           11  27727414  2015-01-01T00:07:28.747     1210038     javascript\n",
      "12           12  27727418  2015-01-01T00:07:39.243     3674356            php\n",
      "13           13  27727419  2015-01-01T00:07:46.460      347062           html\n",
      "14           14  27727424  2015-01-01T00:09:28.247     1254618        collada\n",
      "15           15  27727427  2015-01-01T00:10:05.340     3412951  ruby-on-rails\n",
      "16           16  27727429  2015-01-01T00:10:29.963     1743377     javascript\n",
      "17           17  27727433  2015-01-01T00:11:43.463      169992              c\n",
      "18           18  27727434  2015-01-01T00:12:02.597     4056620            ios\n",
      "19           19  27727439  2015-01-01T00:12:55.513     2993567           java\n",
      "20           20  27727442  2015-01-01T00:13:04.980     3085148     powershell\n",
      "21           21  27727444  2015-01-01T00:13:32.583     2457761           java\n",
      "22           22  27727446  2015-01-01T00:13:50.463     4371259        node.js\n",
      "23           23  27727455  2015-01-01T00:15:40.250     3802790            ios\n",
      "24           24  27727459  2015-01-01T00:17:11.113     2227834              c\n",
      "25           25  27727464  2015-01-01T00:18:50.297     4397115     javascript\n",
      "26           26  27727468  2015-01-01T00:22:16.780     3494499            ios\n",
      "27           27  27727477  2015-01-01T00:23:14.747     3286192        android\n",
      "28           28  27727481  2015-01-01T00:23:50.863     2999675            c++\n",
      "29           29  27727484  2015-01-01T00:24:28.103     4289580            php\n",
      "..          ...       ...                      ...         ...            ...\n",
      "970         970  27730588  2015-01-01T11:56:42.857     1302750        signalr\n",
      "971         971  27730594  2015-01-01T11:57:26.953     4401878            php\n",
      "972         972  27730595  2015-01-01T11:57:57.223     4409044           html\n",
      "973         973  27730598  2015-01-01T11:58:19.533     4399627           java\n",
      "974         974  27730600  2015-01-01T11:58:43.297     3483542              r\n",
      "975         975  27730605  2015-01-01T11:59:12.783     4359756           html\n",
      "976         976  27730607  2015-01-01T11:59:15.720     1789384        tomcat7\n",
      "977         977  27730610  2015-01-01T11:59:24.317     3646990      worklight\n",
      "978         978  27730611  2015-01-01T12:00:02.167     4384866            c++\n",
      "979         979  27730619  2015-01-01T12:01:34.303     3395776            php\n",
      "980         980  27730620  2015-01-01T12:01:43.020     4386925           bash\n",
      "981         981  27730621  2015-01-01T12:01:50.490     4410056        android\n",
      "982         982  27730622  2015-01-01T12:01:59.117      862948   web-services\n",
      "983         983  27730623  2015-01-01T12:02:00.307     2132128            c++\n",
      "984         984  27730626  2015-01-01T12:02:41.387     3350569        cordova\n",
      "985         985  27730627  2015-01-01T12:03:07.887     4410080            ios\n",
      "986         986  27730628  2015-01-01T12:03:47.710      587021        mongodb\n",
      "987         987  27730629  2015-01-01T12:04:27.137     2446345            ios\n",
      "988         988  27730632  2015-01-01T12:05:00.063     2777324            php\n",
      "989         989  27730633  2015-01-01T12:05:07.847     1525840            wpf\n",
      "990         990  27730634  2015-01-01T12:05:11.827     2357956        android\n",
      "991         991  27730636  2015-01-01T12:05:19.007     2455896            php\n",
      "992         992  27730637  2015-01-01T12:05:23.707     1135245        android\n",
      "993         993  27730642  2015-01-01T12:06:10.650      707700     javascript\n",
      "994         994  27730644  2015-01-01T12:06:11.700     2169170      .htaccess\n",
      "995         995  27730650  2015-01-01T12:07:01.710     3939458      angularjs\n",
      "996         996  27730657  2015-01-01T12:08:32.147     4410088         jekyll\n",
      "997         997  27730658  2015-01-01T12:08:34.727     1066642            ios\n",
      "998         998  27730663  2015-01-01T12:09:34.937      276439           html\n",
      "999         999  27730667  2015-01-01T12:09:50.367     2155425           java\n",
      "\n",
      "[1000 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "fetchData()\n",
    "question_df = pd.read_csv('question_dataframe_sample.csv')\n",
    "print question_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3. Putting it all together"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are now ready to tackle our original problem. Write a function to measure the similarity of the top 1000 users with the most answer posts. Compare the users based on the types of questions they answer. We will categorize the questions by looking at the first tag in each question. You may choose to implement any one of the similarity/distance measures we discussed in class. Document your findings. **(30pts)**\n",
    "\n",
    "Note that answers are posts with `PostTypeId=2`. The ID of the question in answer posts is the `ParentId`.\n",
    "\n",
    "You may find the [sklearn.feature_extraction module](http://scikit-learn.org/stable/modules/feature_extraction.html) helpful."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot the top 100 most similar users. See [Lecture 3](https://github.com/datascience16/lectures/blob/master/Lecture3/Distance-Functions.ipynb) for examples. **(10 pts)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, let's create some time series from the data. Look at the top 100 users with the most question posts. For each user, your time series will be the `CreationDate` of the questions posted by that user. You may want to make multiple time series for each user based on the first tag of the questions. Compare the time series using one of the methods discussed in class. Document your findings. **(30 pts)**\n",
    "\n",
    "You may find the [pandas.DataFrame.resample module](http://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.resample.html) helpful."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot the 2 most similar and the 2 most different time series. **(10 pts)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Code for setting the style of the notebook\n",
    "from IPython.core.display import HTML\n",
    "def css_styling():\n",
    "    styles = open(\"../theme/custom.css\", \"r\").read()\n",
    "    return HTML(styles)\n",
    "css_styling()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
